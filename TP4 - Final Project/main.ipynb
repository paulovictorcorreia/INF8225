{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We are building a machine learning pipeline for classification of EEG signals.\n",
    "\n",
    "Preprocessing files will be run separetely from this notebook, and we will import their variables.\n",
    "\n",
    "This notebook will focus on creating the pipeline for assessing the best model to detect seizures in EEG signals. We will use three main strategies:\n",
    "\n",
    "* Res2Net Transformer\n",
    "* 1D-CNN + LSTM \n",
    "* Gated 2 Tower Transformer "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.0.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lightning.pytorch as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "y_train = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "y_test = torch.FloatTensor(y_test).unsqueeze(1)\n",
    "y_val = torch.FloatTensor(y_val).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, features, target) -> None:\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = {}\n",
    "        features = self.features[index]\n",
    "        target = self.target[index]\n",
    "        data[\"X\"] = features\n",
    "        data[\"y\"] = target\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_dataloader = DataLoader(EEGDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(EEGDataset(X_val, y_val), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(EEGDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def training(\n",
    "        model, train_dataloader=None, val_dataloader=None,\n",
    "        epochs=5, lr=0.001, device='cpu'):\n",
    "    model = model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    len_train_dataset = len(train_dataloader.dataset)\n",
    "    len_val_dataset = len(val_dataloader.dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for i, data in enumerate(train_dataloader, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            X, y = data[\"X\"].to(device), data[\"y\"].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(X)\n",
    "            train_loss = criterion(outputs, y)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += train_loss.item()\n",
    "        \n",
    "        \n",
    "        validation_loss = 0\n",
    "        for j, data in enumerate(val_dataloader, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            X, y = data[\"X\"].to(device), data[\"y\"].to(device)\n",
    "\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            with torch.no_grad():\n",
    "                outputs = model(X)\n",
    "                val_loss = criterion(outputs, y)\n",
    "                # print statistics\n",
    "                validation_loss += val_loss.item()\n",
    "        print(f\"Epoch: {epoch}\\tTraining loss: {running_loss/i:.5f}\\t\\t Validation Loss: {validation_loss/j:.5f}\")\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTraining loss: 0.51512\t\t Validation Loss: 0.50043\n",
      "Epoch: 1\tTraining loss: 0.50239\t\t Validation Loss: 0.50351\n",
      "Epoch: 2\tTraining loss: 0.50137\t\t Validation Loss: 0.50125\n",
      "Epoch: 3\tTraining loss: 0.50211\t\t Validation Loss: 0.49863\n",
      "Epoch: 4\tTraining loss: 0.50000\t\t Validation Loss: 0.49773\n",
      "Epoch: 5\tTraining loss: 0.49654\t\t Validation Loss: 0.49064\n",
      "Epoch: 6\tTraining loss: 0.49327\t\t Validation Loss: 0.48968\n",
      "Epoch: 7\tTraining loss: 0.49259\t\t Validation Loss: 0.50155\n",
      "Epoch: 8\tTraining loss: 0.49665\t\t Validation Loss: 0.50193\n",
      "Epoch: 9\tTraining loss: 0.49879\t\t Validation Loss: 0.49901\n",
      "Epoch: 10\tTraining loss: 0.49472\t\t Validation Loss: 0.49771\n",
      "Epoch: 11\tTraining loss: 0.48740\t\t Validation Loss: 0.47974\n",
      "Epoch: 12\tTraining loss: 0.48977\t\t Validation Loss: 0.49954\n",
      "Epoch: 13\tTraining loss: 0.49677\t\t Validation Loss: 0.48971\n",
      "Epoch: 14\tTraining loss: 0.49107\t\t Validation Loss: 0.49076\n"
     ]
    }
   ],
   "source": [
    "class CNN_LSTM_Classifier(pl.LightningModule):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv1d(1, 64, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool1d(2, 2)\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 512, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 1024, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten_layer = nn.Linear(82, 256)\n",
    "        dropout = 0.2\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.lstm = nn.LSTM(1024, 64, 2, batch_first=True, dropout=dropout)\n",
    "\n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, X: torch.FloatTensor, y=None):\n",
    "        X = X.transpose(1, 2)\n",
    "        out = self.relu(self.conv_1(X))\n",
    "        out = self.max_pool(out)\n",
    "        out = self.conv_layers(out)\n",
    "        out = self.flatten_layer(out)\n",
    "        out = out.transpose(1, 2)\n",
    "        out, (_, _) = self.lstm(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "    \n",
    "model = CNN_LSTM_Classifier()\n",
    "model = training(model, train_dataloader, val_dataloader, device=DEVICE, epochs=15)\n",
    "# model(X_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf8225",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
