{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We are building a machine learning pipeline for classification of EEG signals.\n",
    "\n",
    "Preprocessing files will be run separetely from this notebook, and we will import their variables.\n",
    "\n",
    "This notebook will focus on creating the pipeline for assessing the best model to detect seizures in EEG signals. We will use three main strategies:\n",
    "\n",
    "* Res2Net Transformer\n",
    "* 1D-CNN + LSTM \n",
    "* Gated 2 Tower Transformer "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.0.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lightning.pytorch as pl\n",
    "import pickle\n",
    "import copy\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "y_train = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "y_test = torch.FloatTensor(y_test).unsqueeze(1)\n",
    "y_val = torch.FloatTensor(y_val).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1.]), tensor([6440, 1610]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, features, target) -> None:\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = {}\n",
    "        features = self.features[index]\n",
    "        target = self.target[index]\n",
    "        data[\"X\"] = features\n",
    "        data[\"y\"] = target\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_EPOCHS = 75\n",
    "LEARNING_RATE = 1e-4\n",
    "train_dataloader = DataLoader(EEGDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(EEGDataset(X_val, y_val), batch_size=BATCH_SIZE, shuffle=False)\n",
    "final_train_dataloader = DataLoader(EEGDataset(torch.cat((X_train, X_val), 0), torch.cat((y_train, y_val), 0)), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(EEGDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def training(\n",
    "        model, train_dataloader=None, val_dataloader=None,\n",
    "        epochs=5, lr=0.001, device='cpu', earlystopping_tolerance=5):\n",
    "    model = model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([9200/2300]).to(device))\n",
    "    # criterion = nn.BCELoss()\n",
    "    model_state = {\n",
    "        \"model\": None,\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_precision\": [],\n",
    "        \"val_recall\": [],\n",
    "        \"val_f1\": [],\n",
    "    }\n",
    "    best_validation = np.inf\n",
    "    best_model = None\n",
    "    count_tolerance = 0\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0\n",
    "\n",
    "        val_predictions = []\n",
    "        val_groundtruth = []\n",
    "        for i, data in enumerate(train_dataloader, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            X, y = data[\"X\"].to(device), data[\"y\"].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(X)\n",
    "            train_loss = criterion(outputs, y)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            training_loss += train_loss.item()\n",
    "        \n",
    "        training_loss /= i\n",
    "        \n",
    "        if isinstance(val_dataloader, DataLoader):\n",
    "            validation_loss = 0\n",
    "            for j, data in enumerate(val_dataloader, 1):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                X, y = data[\"X\"].to(device), data[\"y\"].to(device)\n",
    "                val_groundtruth.append(y)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(X)\n",
    "                    val_predictions.append(torch.sigmoid(outputs))\n",
    "                    val_loss = criterion(outputs, y)\n",
    "                    # print statistics\n",
    "                    validation_loss += val_loss.item()\n",
    "            val_groundtruth = torch.cat(val_groundtruth, axis=0).cpu().squeeze(-1).detach().numpy()\n",
    "            val_predictions = torch.cat(val_predictions, axis=0).cpu().squeeze(-1).detach().numpy()\n",
    "            val_predictions = (val_predictions > 0.5).astype(np.int16)\n",
    "            val_acc = accuracy_score(val_groundtruth, val_predictions)\n",
    "            val_precision = precision_score(val_groundtruth, val_predictions)\n",
    "            val_recall = recall_score(val_groundtruth, val_predictions)\n",
    "            val_f1 = f1_score(val_groundtruth, val_predictions)\n",
    "\n",
    "            validation_loss /= j\n",
    "            \n",
    "            if (validation_loss) < best_validation:\n",
    "                count_tolerance = 0\n",
    "                best_validation = validation_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "            \n",
    "            count_tolerance += 1\n",
    "            print(f\"Epoch: {epoch}\\tTraining loss: {training_loss:.5f}\\t\\t Validation Loss: {validation_loss:.5f}\\tValidation Accuracy: {val_acc:.5f}\")\n",
    "            model_state[\"train_loss\"].append(training_loss)\n",
    "            model_state[\"val_loss\"].append(validation_loss)\n",
    "            model_state[\"val_acc\"].append(val_acc)\n",
    "            model_state[\"val_precision\"].append(val_precision)\n",
    "            model_state[\"val_recall\"].append(val_recall)\n",
    "            model_state[\"val_f1\"].append(val_f1)\n",
    "\n",
    "            if count_tolerance >= earlystopping_tolerance:\n",
    "                break\n",
    "            \n",
    "        else:\n",
    "            print(f\"Epoch: {epoch}\\tTraining loss: {training_loss:.5f}\")\n",
    "            model_state[\"train_loss\"].append(training_loss)\n",
    "            best_model = copy.deepcopy(model)\n",
    "        \n",
    "    \n",
    "    model_state[\"model\"] = best_model\n",
    "    save_model(model_state)\n",
    "    torch.cuda.empty_cache()\n",
    "    return model_state\n",
    "\n",
    "def save_model(model_state):\n",
    "    with open(f\"models/{ model_state['model'].to_string() }.pkl\", \"wb\") as fp:\n",
    "        model_state[\"model\"] = model_state[\"model\"].to(\"cpu\").state_dict()\n",
    "        pickle.dump(model_state, fp)\n",
    "        print(\"Saved model successfully!\")\n",
    "\n",
    "# def test_accuracy_score(model, test_dataloader):\n",
    "#     y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTraining loss: 1.10964\t\t Validation Loss: 1.10850\tValidation Accuracy: 0.20000\n",
      "Epoch: 1\tTraining loss: 1.07053\t\t Validation Loss: 0.96781\tValidation Accuracy: 0.81507\n",
      "Epoch: 2\tTraining loss: 0.76647\t\t Validation Loss: 0.58139\tValidation Accuracy: 0.84812\n",
      "Epoch: 3\tTraining loss: 0.52342\t\t Validation Loss: 0.40535\tValidation Accuracy: 0.90899\n",
      "Epoch: 4\tTraining loss: 0.40667\t\t Validation Loss: 0.29368\tValidation Accuracy: 0.92580\n",
      "Epoch: 5\tTraining loss: 0.33562\t\t Validation Loss: 0.27014\tValidation Accuracy: 0.92116\n",
      "Epoch: 6\tTraining loss: 0.27964\t\t Validation Loss: 0.36268\tValidation Accuracy: 0.95188\n",
      "Epoch: 7\tTraining loss: 0.22383\t\t Validation Loss: 0.23542\tValidation Accuracy: 0.95884\n",
      "Epoch: 8\tTraining loss: 0.19761\t\t Validation Loss: 0.22125\tValidation Accuracy: 0.94725\n",
      "Epoch: 9\tTraining loss: 0.17515\t\t Validation Loss: 0.25535\tValidation Accuracy: 0.94493\n",
      "Epoch: 10\tTraining loss: 0.16270\t\t Validation Loss: 0.22548\tValidation Accuracy: 0.93159\n",
      "Epoch: 11\tTraining loss: 0.15375\t\t Validation Loss: 0.24503\tValidation Accuracy: 0.95304\n",
      "Epoch: 12\tTraining loss: 0.12961\t\t Validation Loss: 0.68471\tValidation Accuracy: 0.94841\n",
      "Epoch: 13\tTraining loss: 0.14017\t\t Validation Loss: 0.27773\tValidation Accuracy: 0.95710\n",
      "Epoch: 14\tTraining loss: 0.10458\t\t Validation Loss: 0.26217\tValidation Accuracy: 0.97275\n",
      "Epoch: 15\tTraining loss: 0.09079\t\t Validation Loss: 0.25134\tValidation Accuracy: 0.96870\n",
      "Epoch: 16\tTraining loss: 0.11396\t\t Validation Loss: 0.41656\tValidation Accuracy: 0.96638\n",
      "Epoch: 17\tTraining loss: 0.07715\t\t Validation Loss: 0.23832\tValidation Accuracy: 0.94667\n",
      "Epoch: 18\tTraining loss: 0.08603\t\t Validation Loss: 0.23096\tValidation Accuracy: 0.96000\n",
      "Epoch: 19\tTraining loss: 0.06650\t\t Validation Loss: 0.28599\tValidation Accuracy: 0.93507\n",
      "Epoch: 20\tTraining loss: 0.07797\t\t Validation Loss: 0.24247\tValidation Accuracy: 0.97333\n",
      "Epoch: 21\tTraining loss: 0.06013\t\t Validation Loss: 0.24350\tValidation Accuracy: 0.97043\n",
      "Epoch: 22\tTraining loss: 0.05342\t\t Validation Loss: 0.25575\tValidation Accuracy: 0.96928\n",
      "Epoch: 23\tTraining loss: 0.05895\t\t Validation Loss: 0.36302\tValidation Accuracy: 0.96696\n",
      "Epoch: 24\tTraining loss: 0.06237\t\t Validation Loss: 0.24852\tValidation Accuracy: 0.95536\n",
      "Epoch: 25\tTraining loss: 0.04899\t\t Validation Loss: 0.25634\tValidation Accuracy: 0.97275\n",
      "Epoch: 26\tTraining loss: 0.03952\t\t Validation Loss: 0.25500\tValidation Accuracy: 0.97101\n",
      "Epoch: 27\tTraining loss: 0.02920\t\t Validation Loss: 0.51934\tValidation Accuracy: 0.97217\n",
      "Epoch: 28\tTraining loss: 0.07222\t\t Validation Loss: 0.26004\tValidation Accuracy: 0.97391\n",
      "Epoch: 29\tTraining loss: 0.02212\t\t Validation Loss: 0.27944\tValidation Accuracy: 0.96812\n",
      "Epoch: 30\tTraining loss: 0.04377\t\t Validation Loss: 0.27898\tValidation Accuracy: 0.95768\n",
      "Epoch: 31\tTraining loss: 0.03109\t\t Validation Loss: 0.31970\tValidation Accuracy: 0.97449\n",
      "Epoch: 32\tTraining loss: 0.02857\t\t Validation Loss: 0.34557\tValidation Accuracy: 0.95768\n",
      "Epoch: 33\tTraining loss: 0.03712\t\t Validation Loss: 0.31297\tValidation Accuracy: 0.97507\n",
      "Epoch: 34\tTraining loss: 0.05188\t\t Validation Loss: 0.32953\tValidation Accuracy: 0.97449\n",
      "Epoch: 35\tTraining loss: 0.01002\t\t Validation Loss: 0.34847\tValidation Accuracy: 0.97449\n",
      "Epoch: 36\tTraining loss: 0.00685\t\t Validation Loss: 0.33858\tValidation Accuracy: 0.96812\n",
      "Epoch: 37\tTraining loss: 0.02181\t\t Validation Loss: 0.34253\tValidation Accuracy: 0.97507\n",
      "Epoch: 38\tTraining loss: 0.03853\t\t Validation Loss: 0.49487\tValidation Accuracy: 0.96290\n",
      "Epoch: 39\tTraining loss: 0.03456\t\t Validation Loss: 0.42662\tValidation Accuracy: 0.97275\n",
      "Epoch: 40\tTraining loss: 0.07932\t\t Validation Loss: 0.33486\tValidation Accuracy: 0.96986\n",
      "Epoch: 41\tTraining loss: 0.00601\t\t Validation Loss: 0.33164\tValidation Accuracy: 0.96174\n",
      "Epoch: 42\tTraining loss: 0.01390\t\t Validation Loss: 0.36645\tValidation Accuracy: 0.96638\n",
      "Epoch: 43\tTraining loss: 0.01175\t\t Validation Loss: 0.44249\tValidation Accuracy: 0.97507\n",
      "Epoch: 44\tTraining loss: 0.03673\t\t Validation Loss: 0.27135\tValidation Accuracy: 0.97391\n",
      "Epoch: 45\tTraining loss: 0.00569\t\t Validation Loss: 0.33843\tValidation Accuracy: 0.97681\n",
      "Epoch: 46\tTraining loss: 0.00108\t\t Validation Loss: 0.35099\tValidation Accuracy: 0.97449\n",
      "Epoch: 47\tTraining loss: 0.01467\t\t Validation Loss: 0.67087\tValidation Accuracy: 0.96290\n",
      "Epoch: 48\tTraining loss: 0.03208\t\t Validation Loss: 0.41963\tValidation Accuracy: 0.97681\n",
      "Epoch: 49\tTraining loss: 0.01554\t\t Validation Loss: 0.28122\tValidation Accuracy: 0.95826\n",
      "Epoch: 50\tTraining loss: 0.03052\t\t Validation Loss: 0.39325\tValidation Accuracy: 0.97275\n",
      "Epoch: 51\tTraining loss: 0.01153\t\t Validation Loss: 0.27635\tValidation Accuracy: 0.97217\n",
      "Epoch: 52\tTraining loss: 0.00813\t\t Validation Loss: 0.40769\tValidation Accuracy: 0.97739\n",
      "Epoch: 53\tTraining loss: 0.03029\t\t Validation Loss: 0.29118\tValidation Accuracy: 0.95362\n",
      "Epoch: 54\tTraining loss: 0.02893\t\t Validation Loss: 0.47929\tValidation Accuracy: 0.96754\n",
      "Epoch: 55\tTraining loss: 0.02631\t\t Validation Loss: 0.34803\tValidation Accuracy: 0.97565\n",
      "Epoch: 56\tTraining loss: 0.00198\t\t Validation Loss: 0.45042\tValidation Accuracy: 0.97797\n",
      "Epoch: 57\tTraining loss: 0.00081\t\t Validation Loss: 0.35900\tValidation Accuracy: 0.97797\n",
      "Epoch: 58\tTraining loss: 0.00024\t\t Validation Loss: 0.40225\tValidation Accuracy: 0.97797\n",
      "Epoch: 59\tTraining loss: 0.00029\t\t Validation Loss: 0.38130\tValidation Accuracy: 0.97913\n",
      "Epoch: 60\tTraining loss: 0.00020\t\t Validation Loss: 0.46026\tValidation Accuracy: 0.97681\n",
      "Epoch: 61\tTraining loss: 0.00011\t\t Validation Loss: 0.45008\tValidation Accuracy: 0.97971\n",
      "Epoch: 62\tTraining loss: 0.00007\t\t Validation Loss: 0.46179\tValidation Accuracy: 0.97739\n",
      "Epoch: 63\tTraining loss: 0.00007\t\t Validation Loss: 0.46291\tValidation Accuracy: 0.97797\n",
      "Epoch: 64\tTraining loss: 0.00006\t\t Validation Loss: 0.48986\tValidation Accuracy: 0.97739\n",
      "Epoch: 65\tTraining loss: 0.00006\t\t Validation Loss: 0.47089\tValidation Accuracy: 0.97913\n",
      "Epoch: 66\tTraining loss: 0.00003\t\t Validation Loss: 0.52109\tValidation Accuracy: 0.97797\n",
      "Epoch: 67\tTraining loss: 0.00008\t\t Validation Loss: 0.51772\tValidation Accuracy: 0.97855\n",
      "Epoch: 68\tTraining loss: 0.00003\t\t Validation Loss: 0.53270\tValidation Accuracy: 0.97739\n",
      "Epoch: 69\tTraining loss: 0.00003\t\t Validation Loss: 0.55363\tValidation Accuracy: 0.97855\n",
      "Epoch: 70\tTraining loss: 0.00002\t\t Validation Loss: 0.55980\tValidation Accuracy: 0.97971\n",
      "Epoch: 71\tTraining loss: 0.00001\t\t Validation Loss: 0.60328\tValidation Accuracy: 0.97681\n",
      "Epoch: 72\tTraining loss: 0.00002\t\t Validation Loss: 0.59262\tValidation Accuracy: 0.97681\n",
      "Epoch: 73\tTraining loss: 0.00002\t\t Validation Loss: 0.59250\tValidation Accuracy: 0.97971\n",
      "Epoch: 74\tTraining loss: 0.00001\t\t Validation Loss: 0.61831\tValidation Accuracy: 0.97623\n",
      "Saved model successfully!\n"
     ]
    }
   ],
   "source": [
    "class CNN_LSTM_Classifier(pl.LightningModule):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.device_ = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.conv_1 = nn.Conv1d(1, 64, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool1d(2, 2)\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 512, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 1024, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten_layer = nn.Linear(82, 256)\n",
    "        dropout = 0.2\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.lstm = nn.LSTM(1024, 64, 2, batch_first=True, dropout=dropout)\n",
    "\n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, X: torch.FloatTensor, y=None):\n",
    "        X = X.transpose(1, 2)\n",
    "        out = self.relu(self.conv_1(X))\n",
    "        out = self.max_pool(out)\n",
    "        out = self.conv_layers(out)\n",
    "        out = self.flatten_layer(out)\n",
    "        out = out.transpose(1, 2)\n",
    "        out, (_, _) = self.lstm(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "    \n",
    "    def predict_batch(self, X: torch.FloatTensor):\n",
    "        pred = (torch.sigmoid(self(X)) > 0.5).int()\n",
    "        return pred\n",
    "\n",
    "    def predict(self, dataloader: DataLoader):\n",
    "        predictions = list()\n",
    "        for i, data in enumerate(dataloader, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            with torch.no_grad():\n",
    "                X = data[\"X\"]\n",
    "                y_pred = self.predict_batch(X)\n",
    "                predictions.append(y_pred)\n",
    "        predictions = torch.cat(predictions, 0)\n",
    "        return predictions\n",
    "\n",
    "    def to_string(self):\n",
    "        return \"CNN_LSTM_Classifier\"\n",
    "\n",
    "\n",
    "    \n",
    "model_cnn_lstm = CNN_LSTM_Classifier()\n",
    "state_cnn_lstm = training(model_cnn_lstm, train_dataloader, val_dataloader, device=DEVICE, epochs=NUM_EPOCHS, lr=LEARNING_RATE, earlystopping_tolerance=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(state[\"train_loss\"], label=\"Training Loss\")\n",
    "# plt.plot(state[\"val_loss\"], label=\"Validation Loss\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.title(\"Training x Validation Losses\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Binary Cross Entropy Loss\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnablePositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1024):\n",
    "        super(LearnablePositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        # Each position gets its own embedding\n",
    "        # Since indices are always 0 ... max_len, we don't have to do a look-up\n",
    "        self.pe = nn.Parameter(torch.empty(max_len, 1, d_model))  # requires_grad automatically set to True\n",
    "        nn.init.uniform_(self.pe, -0.02, 0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTraining loss: 1.11994\t\t Validation Loss: 1.10000\tValidation Accuracy: 0.61739\n",
      "Epoch: 1\tTraining loss: 1.00011\t\t Validation Loss: 0.85511\tValidation Accuracy: 0.77043\n",
      "Epoch: 2\tTraining loss: 0.76880\t\t Validation Loss: 0.72057\tValidation Accuracy: 0.76928\n",
      "Epoch: 3\tTraining loss: 0.66724\t\t Validation Loss: 0.71045\tValidation Accuracy: 0.77971\n",
      "Epoch: 4\tTraining loss: 0.60867\t\t Validation Loss: 0.66965\tValidation Accuracy: 0.81391\n",
      "Epoch: 5\tTraining loss: 0.56102\t\t Validation Loss: 0.64398\tValidation Accuracy: 0.82493\n",
      "Epoch: 6\tTraining loss: 0.49510\t\t Validation Loss: 0.62926\tValidation Accuracy: 0.86087\n",
      "Epoch: 7\tTraining loss: 0.43190\t\t Validation Loss: 0.64546\tValidation Accuracy: 0.86551\n",
      "Epoch: 8\tTraining loss: 0.38162\t\t Validation Loss: 0.64019\tValidation Accuracy: 0.84348\n",
      "Epoch: 9\tTraining loss: 0.32003\t\t Validation Loss: 0.58394\tValidation Accuracy: 0.89159\n",
      "Epoch: 10\tTraining loss: 0.26818\t\t Validation Loss: 0.65003\tValidation Accuracy: 0.88696\n",
      "Epoch: 11\tTraining loss: 0.24124\t\t Validation Loss: 0.62404\tValidation Accuracy: 0.86145\n",
      "Epoch: 12\tTraining loss: 0.19812\t\t Validation Loss: 0.64916\tValidation Accuracy: 0.87710\n",
      "Epoch: 13\tTraining loss: 0.16147\t\t Validation Loss: 0.65700\tValidation Accuracy: 0.89159\n",
      "Epoch: 14\tTraining loss: 0.13509\t\t Validation Loss: 0.78495\tValidation Accuracy: 0.88464\n",
      "Epoch: 15\tTraining loss: 0.10824\t\t Validation Loss: 0.90059\tValidation Accuracy: 0.88406\n",
      "Epoch: 16\tTraining loss: 0.10019\t\t Validation Loss: 0.72264\tValidation Accuracy: 0.87652\n",
      "Epoch: 17\tTraining loss: 0.08331\t\t Validation Loss: 0.80156\tValidation Accuracy: 0.88464\n",
      "Epoch: 18\tTraining loss: 0.08213\t\t Validation Loss: 0.77108\tValidation Accuracy: 0.87652\n",
      "Epoch: 19\tTraining loss: 0.05353\t\t Validation Loss: 0.91857\tValidation Accuracy: 0.87884\n",
      "Epoch: 20\tTraining loss: 0.04390\t\t Validation Loss: 1.00135\tValidation Accuracy: 0.88116\n",
      "Epoch: 21\tTraining loss: 0.03597\t\t Validation Loss: 0.97524\tValidation Accuracy: 0.88580\n",
      "Epoch: 22\tTraining loss: 0.03313\t\t Validation Loss: 0.98234\tValidation Accuracy: 0.89391\n",
      "Epoch: 23\tTraining loss: 0.04803\t\t Validation Loss: 0.90489\tValidation Accuracy: 0.88464\n",
      "Epoch: 24\tTraining loss: 0.07322\t\t Validation Loss: 0.84215\tValidation Accuracy: 0.88348\n",
      "Epoch: 25\tTraining loss: 0.04159\t\t Validation Loss: 0.96777\tValidation Accuracy: 0.88696\n",
      "Epoch: 26\tTraining loss: 0.02630\t\t Validation Loss: 0.98127\tValidation Accuracy: 0.88696\n",
      "Epoch: 27\tTraining loss: 0.01452\t\t Validation Loss: 1.07908\tValidation Accuracy: 0.88638\n",
      "Epoch: 28\tTraining loss: 0.00895\t\t Validation Loss: 1.15764\tValidation Accuracy: 0.89449\n",
      "Epoch: 29\tTraining loss: 0.00683\t\t Validation Loss: 1.16840\tValidation Accuracy: 0.88638\n",
      "Epoch: 30\tTraining loss: 0.00583\t\t Validation Loss: 1.18474\tValidation Accuracy: 0.89681\n",
      "Epoch: 31\tTraining loss: 0.00509\t\t Validation Loss: 1.23150\tValidation Accuracy: 0.89333\n",
      "Epoch: 32\tTraining loss: 0.15575\t\t Validation Loss: 0.92480\tValidation Accuracy: 0.87014\n",
      "Epoch: 33\tTraining loss: 0.08526\t\t Validation Loss: 0.93024\tValidation Accuracy: 0.88348\n",
      "Epoch: 34\tTraining loss: 0.02284\t\t Validation Loss: 1.09116\tValidation Accuracy: 0.88928\n",
      "Epoch: 35\tTraining loss: 0.01418\t\t Validation Loss: 1.13674\tValidation Accuracy: 0.89507\n",
      "Epoch: 36\tTraining loss: 0.00848\t\t Validation Loss: 1.16784\tValidation Accuracy: 0.89797\n",
      "Epoch: 37\tTraining loss: 0.00565\t\t Validation Loss: 1.21913\tValidation Accuracy: 0.89391\n",
      "Epoch: 38\tTraining loss: 0.00487\t\t Validation Loss: 1.18853\tValidation Accuracy: 0.89739\n",
      "Epoch: 39\tTraining loss: 0.00506\t\t Validation Loss: 1.25325\tValidation Accuracy: 0.89681\n",
      "Epoch: 40\tTraining loss: 0.00436\t\t Validation Loss: 1.14858\tValidation Accuracy: 0.89159\n",
      "Epoch: 41\tTraining loss: 0.00396\t\t Validation Loss: 1.31518\tValidation Accuracy: 0.89275\n",
      "Epoch: 42\tTraining loss: 0.00270\t\t Validation Loss: 1.38671\tValidation Accuracy: 0.89739\n",
      "Epoch: 43\tTraining loss: 0.00220\t\t Validation Loss: 1.35730\tValidation Accuracy: 0.89449\n",
      "Epoch: 44\tTraining loss: 0.00204\t\t Validation Loss: 1.44896\tValidation Accuracy: 0.90203\n",
      "Epoch: 45\tTraining loss: 0.00175\t\t Validation Loss: 1.43227\tValidation Accuracy: 0.89507\n",
      "Epoch: 46\tTraining loss: 0.00149\t\t Validation Loss: 1.64402\tValidation Accuracy: 0.89971\n",
      "Epoch: 47\tTraining loss: 0.00138\t\t Validation Loss: 1.46295\tValidation Accuracy: 0.89043\n",
      "Epoch: 48\tTraining loss: 0.09433\t\t Validation Loss: 0.87675\tValidation Accuracy: 0.88000\n",
      "Epoch: 49\tTraining loss: 0.10184\t\t Validation Loss: 1.23097\tValidation Accuracy: 0.89275\n",
      "Epoch: 50\tTraining loss: 0.01821\t\t Validation Loss: 1.22699\tValidation Accuracy: 0.89507\n",
      "Epoch: 51\tTraining loss: 0.01193\t\t Validation Loss: 1.28744\tValidation Accuracy: 0.90203\n",
      "Epoch: 52\tTraining loss: 0.00493\t\t Validation Loss: 1.24036\tValidation Accuracy: 0.90435\n",
      "Epoch: 53\tTraining loss: 0.00395\t\t Validation Loss: 1.28274\tValidation Accuracy: 0.90203\n",
      "Epoch: 54\tTraining loss: 0.00285\t\t Validation Loss: 1.43595\tValidation Accuracy: 0.89855\n",
      "Epoch: 55\tTraining loss: 0.00229\t\t Validation Loss: 1.36822\tValidation Accuracy: 0.89159\n",
      "Epoch: 56\tTraining loss: 0.00180\t\t Validation Loss: 1.43382\tValidation Accuracy: 0.90145\n",
      "Epoch: 57\tTraining loss: 0.00152\t\t Validation Loss: 1.38840\tValidation Accuracy: 0.89623\n",
      "Epoch: 58\tTraining loss: 0.00141\t\t Validation Loss: 1.42946\tValidation Accuracy: 0.89623\n",
      "Epoch: 59\tTraining loss: 0.00123\t\t Validation Loss: 1.51706\tValidation Accuracy: 0.89797\n",
      "Epoch: 60\tTraining loss: 0.00102\t\t Validation Loss: 1.46602\tValidation Accuracy: 0.89913\n",
      "Epoch: 61\tTraining loss: 0.00106\t\t Validation Loss: 1.55538\tValidation Accuracy: 0.89797\n",
      "Epoch: 62\tTraining loss: 0.13840\t\t Validation Loss: 1.02491\tValidation Accuracy: 0.88464\n",
      "Epoch: 63\tTraining loss: 0.02214\t\t Validation Loss: 1.20516\tValidation Accuracy: 0.89739\n",
      "Epoch: 64\tTraining loss: 0.00826\t\t Validation Loss: 1.23157\tValidation Accuracy: 0.88522\n",
      "Epoch: 65\tTraining loss: 0.00495\t\t Validation Loss: 1.43855\tValidation Accuracy: 0.89275\n",
      "Epoch: 66\tTraining loss: 0.00351\t\t Validation Loss: 1.32812\tValidation Accuracy: 0.89739\n",
      "Epoch: 67\tTraining loss: 0.00238\t\t Validation Loss: 1.51091\tValidation Accuracy: 0.89623\n",
      "Epoch: 68\tTraining loss: 0.00250\t\t Validation Loss: 1.48291\tValidation Accuracy: 0.90261\n",
      "Epoch: 69\tTraining loss: 0.00154\t\t Validation Loss: 1.43387\tValidation Accuracy: 0.89449\n",
      "Epoch: 70\tTraining loss: 0.00122\t\t Validation Loss: 1.51661\tValidation Accuracy: 0.89739\n",
      "Epoch: 71\tTraining loss: 0.00109\t\t Validation Loss: 1.55210\tValidation Accuracy: 0.89971\n",
      "Epoch: 72\tTraining loss: 0.00118\t\t Validation Loss: 1.58515\tValidation Accuracy: 0.89913\n",
      "Epoch: 73\tTraining loss: 0.04761\t\t Validation Loss: 1.00536\tValidation Accuracy: 0.88116\n",
      "Epoch: 74\tTraining loss: 0.04606\t\t Validation Loss: 1.34281\tValidation Accuracy: 0.87652\n",
      "Saved model successfully!\n"
     ]
    }
   ],
   "source": [
    "class GatedTransformerNet(nn.Module):\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.device = device \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.d_model = 512\n",
    "\n",
    "        self.step_embedding = nn.Linear(1, self.d_model)\n",
    "        self.channel_embedding = nn.Linear(1, self.d_model)\n",
    "        self.positional_embedding = PositionalEncoding(d_model=self.d_model, dropout=0.2)\n",
    "        # self.positional_embedding = LearnablePositionalEncoding(d_model=self.d_model, dropout=0.2, max_len=512)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.step_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(self.d_model, nhead=8, batch_first=True), num_layers=2)\n",
    "        self.channel_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(self.d_model, nhead=8, batch_first=True), num_layers=2)\n",
    "\n",
    "        self.gating = nn.Linear(self.d_model*178*2, 2)\n",
    "\n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Linear(self.d_model*178*2, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "\n",
    "        )\n",
    "    \n",
    "    def generate_square_subsequent_mask(self, sz: int) -> torch.Tensor:\n",
    "        \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "        return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1).to(self.device)\n",
    "\n",
    "\n",
    "    def forward(self, X: torch.FloatTensor, y=None):\n",
    "        batch_size = X.shape[0]\n",
    "        seq_len = X.shape[1]\n",
    "        mask = self.generate_square_subsequent_mask(seq_len)\n",
    "\n",
    "        channel = self.tanh(self.channel_embedding(X))\n",
    "        channel = self.dropout(self.channel_encoder(channel))\n",
    "\n",
    "        step = self.tanh(self.step_embedding(X))\n",
    "        step = step.transpose(0, 1)\n",
    "        step = self.positional_embedding(step)\n",
    "        step = step.transpose(0, 1)\n",
    "\n",
    "\n",
    "        step = self.dropout(self.step_encoder(step, mask))\n",
    "\n",
    "        channel = channel.reshape(batch_size, -1)\n",
    "        step = step.reshape(batch_size, -1)\n",
    "\n",
    "        concat = torch.cat([channel, step], -1)\n",
    "        h = self.gating(concat)\n",
    "        gate = torch.softmax(h, dim=-1)\n",
    "\n",
    "\n",
    "        encoding = torch.cat([channel * gate[:, 0:1], step * gate[:, 1:2]], dim=-1)\n",
    "        encoding = self.dropout(encoding)\n",
    "        out = self.fc_out(encoding)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def predict_batch(self, X: torch.FloatTensor):\n",
    "        pred = (torch.sigmoid(self(X)) > 0.5).int()\n",
    "        return pred\n",
    "\n",
    "    def predict(self, dataloader: DataLoader):\n",
    "        predictions = list()\n",
    "        for i, data in enumerate(dataloader, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            with torch.no_grad():\n",
    "                X = data[\"X\"]\n",
    "                y_pred = self.predict_batch(X)\n",
    "                predictions.append(y_pred)\n",
    "        predictions = torch.cat(predictions, 0)\n",
    "        return predictions\n",
    "\n",
    "    def to_string(self):\n",
    "        return \"GatedTransformerNet\"\n",
    "\n",
    "model_gated_transformer = GatedTransformerNet(device=DEVICE)\n",
    "state_gated_transformer = training(model_gated_transformer, train_dataloader, val_dataloader, device=DEVICE, epochs=NUM_EPOCHS, lr=LEARNING_RATE, earlystopping_tolerance=NUM_EPOCHS)\n",
    "# model(X_train[:32].to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTraining loss: 1.05881\t\t Validation Loss: 0.93999\tValidation Accuracy: 0.73681\n",
      "Epoch: 1\tTraining loss: 0.87763\t\t Validation Loss: 0.84565\tValidation Accuracy: 0.75072\n",
      "Epoch: 2\tTraining loss: 0.80970\t\t Validation Loss: 0.83131\tValidation Accuracy: 0.81391\n",
      "Epoch: 3\tTraining loss: 0.76696\t\t Validation Loss: 0.79101\tValidation Accuracy: 0.79768\n",
      "Epoch: 4\tTraining loss: 0.73102\t\t Validation Loss: 0.76352\tValidation Accuracy: 0.79478\n",
      "Epoch: 5\tTraining loss: 0.70028\t\t Validation Loss: 0.77266\tValidation Accuracy: 0.80580\n",
      "Epoch: 6\tTraining loss: 0.67705\t\t Validation Loss: 0.75263\tValidation Accuracy: 0.82203\n",
      "Epoch: 7\tTraining loss: 0.66391\t\t Validation Loss: 0.79174\tValidation Accuracy: 0.83594\n",
      "Epoch: 8\tTraining loss: 0.63080\t\t Validation Loss: 0.76847\tValidation Accuracy: 0.82841\n",
      "Epoch: 9\tTraining loss: 0.61500\t\t Validation Loss: 0.76019\tValidation Accuracy: 0.83478\n",
      "Epoch: 10\tTraining loss: 0.58734\t\t Validation Loss: 0.75094\tValidation Accuracy: 0.83594\n",
      "Epoch: 11\tTraining loss: 0.57536\t\t Validation Loss: 0.77876\tValidation Accuracy: 0.82667\n",
      "Epoch: 12\tTraining loss: 0.55395\t\t Validation Loss: 0.75079\tValidation Accuracy: 0.80058\n",
      "Epoch: 13\tTraining loss: 0.52949\t\t Validation Loss: 0.77372\tValidation Accuracy: 0.83014\n",
      "Epoch: 14\tTraining loss: 0.50719\t\t Validation Loss: 0.84258\tValidation Accuracy: 0.84174\n",
      "Epoch: 15\tTraining loss: 0.49136\t\t Validation Loss: 0.80606\tValidation Accuracy: 0.85043\n",
      "Epoch: 16\tTraining loss: 0.49128\t\t Validation Loss: 0.80758\tValidation Accuracy: 0.82609\n",
      "Epoch: 17\tTraining loss: 0.46209\t\t Validation Loss: 0.82515\tValidation Accuracy: 0.83014\n",
      "Epoch: 18\tTraining loss: 0.45297\t\t Validation Loss: 0.80114\tValidation Accuracy: 0.80174\n",
      "Epoch: 19\tTraining loss: 0.45050\t\t Validation Loss: 0.81349\tValidation Accuracy: 0.83710\n",
      "Epoch: 20\tTraining loss: 0.42355\t\t Validation Loss: 0.85029\tValidation Accuracy: 0.79072\n",
      "Epoch: 21\tTraining loss: 0.41521\t\t Validation Loss: 0.85888\tValidation Accuracy: 0.85623\n",
      "Epoch: 22\tTraining loss: 0.38738\t\t Validation Loss: 0.86412\tValidation Accuracy: 0.82319\n",
      "Epoch: 23\tTraining loss: 0.37695\t\t Validation Loss: 0.91897\tValidation Accuracy: 0.82841\n",
      "Epoch: 24\tTraining loss: 0.36910\t\t Validation Loss: 0.88446\tValidation Accuracy: 0.83014\n",
      "Epoch: 25\tTraining loss: 0.33098\t\t Validation Loss: 0.96356\tValidation Accuracy: 0.84232\n",
      "Epoch: 26\tTraining loss: 0.33299\t\t Validation Loss: 0.96392\tValidation Accuracy: 0.83246\n",
      "Epoch: 27\tTraining loss: 0.33463\t\t Validation Loss: 0.88850\tValidation Accuracy: 0.82725\n",
      "Epoch: 28\tTraining loss: 0.31378\t\t Validation Loss: 0.99790\tValidation Accuracy: 0.84232\n",
      "Epoch: 29\tTraining loss: 0.30010\t\t Validation Loss: 0.98701\tValidation Accuracy: 0.84754\n",
      "Epoch: 30\tTraining loss: 0.28642\t\t Validation Loss: 0.92116\tValidation Accuracy: 0.83768\n",
      "Epoch: 31\tTraining loss: 0.28810\t\t Validation Loss: 0.99964\tValidation Accuracy: 0.82957\n",
      "Epoch: 32\tTraining loss: 0.28717\t\t Validation Loss: 1.03679\tValidation Accuracy: 0.86145\n",
      "Epoch: 33\tTraining loss: 0.27084\t\t Validation Loss: 1.09597\tValidation Accuracy: 0.82725\n",
      "Epoch: 34\tTraining loss: 0.25525\t\t Validation Loss: 1.02659\tValidation Accuracy: 0.83246\n",
      "Epoch: 35\tTraining loss: 0.24922\t\t Validation Loss: 0.97662\tValidation Accuracy: 0.83536\n",
      "Epoch: 36\tTraining loss: 0.25448\t\t Validation Loss: 1.04036\tValidation Accuracy: 0.84406\n",
      "Epoch: 37\tTraining loss: 0.24093\t\t Validation Loss: 1.03677\tValidation Accuracy: 0.81971\n",
      "Epoch: 38\tTraining loss: 0.23256\t\t Validation Loss: 1.10527\tValidation Accuracy: 0.81971\n",
      "Epoch: 39\tTraining loss: 0.23303\t\t Validation Loss: 1.10446\tValidation Accuracy: 0.85797\n",
      "Epoch: 40\tTraining loss: 0.21650\t\t Validation Loss: 1.06359\tValidation Accuracy: 0.85449\n",
      "Epoch: 41\tTraining loss: 0.21211\t\t Validation Loss: 1.24373\tValidation Accuracy: 0.83942\n",
      "Epoch: 42\tTraining loss: 0.21096\t\t Validation Loss: 1.30734\tValidation Accuracy: 0.84754\n",
      "Epoch: 43\tTraining loss: 0.18930\t\t Validation Loss: 1.19270\tValidation Accuracy: 0.85217\n",
      "Epoch: 44\tTraining loss: 0.20371\t\t Validation Loss: 1.16740\tValidation Accuracy: 0.83710\n",
      "Epoch: 45\tTraining loss: 0.20578\t\t Validation Loss: 1.10585\tValidation Accuracy: 0.84348\n",
      "Epoch: 46\tTraining loss: 0.19405\t\t Validation Loss: 1.19608\tValidation Accuracy: 0.84754\n",
      "Epoch: 47\tTraining loss: 0.19734\t\t Validation Loss: 1.31472\tValidation Accuracy: 0.84116\n",
      "Epoch: 48\tTraining loss: 0.19033\t\t Validation Loss: 1.11025\tValidation Accuracy: 0.83014\n",
      "Epoch: 49\tTraining loss: 0.18329\t\t Validation Loss: 1.28545\tValidation Accuracy: 0.84174\n",
      "Epoch: 50\tTraining loss: 0.16645\t\t Validation Loss: 1.31877\tValidation Accuracy: 0.85275\n",
      "Epoch: 51\tTraining loss: 0.17368\t\t Validation Loss: 1.36141\tValidation Accuracy: 0.84406\n",
      "Epoch: 52\tTraining loss: 0.16375\t\t Validation Loss: 1.31065\tValidation Accuracy: 0.85159\n",
      "Epoch: 53\tTraining loss: 0.15806\t\t Validation Loss: 1.25672\tValidation Accuracy: 0.84406\n",
      "Epoch: 54\tTraining loss: 0.16724\t\t Validation Loss: 1.22836\tValidation Accuracy: 0.85159\n",
      "Epoch: 55\tTraining loss: 0.17179\t\t Validation Loss: 1.18121\tValidation Accuracy: 0.84928\n",
      "Epoch: 56\tTraining loss: 0.14499\t\t Validation Loss: 1.18569\tValidation Accuracy: 0.85797\n",
      "Epoch: 57\tTraining loss: 0.14882\t\t Validation Loss: 1.24960\tValidation Accuracy: 0.83130\n",
      "Epoch: 58\tTraining loss: 0.15719\t\t Validation Loss: 1.40503\tValidation Accuracy: 0.86145\n",
      "Epoch: 59\tTraining loss: 0.14635\t\t Validation Loss: 1.27817\tValidation Accuracy: 0.85739\n",
      "Epoch: 60\tTraining loss: 0.13870\t\t Validation Loss: 1.25828\tValidation Accuracy: 0.83652\n",
      "Epoch: 61\tTraining loss: 0.14817\t\t Validation Loss: 1.43206\tValidation Accuracy: 0.83652\n",
      "Epoch: 62\tTraining loss: 0.13516\t\t Validation Loss: 1.51365\tValidation Accuracy: 0.86261\n",
      "Epoch: 63\tTraining loss: 0.12624\t\t Validation Loss: 1.27895\tValidation Accuracy: 0.84058\n",
      "Epoch: 64\tTraining loss: 0.12974\t\t Validation Loss: 1.41465\tValidation Accuracy: 0.84928\n",
      "Epoch: 65\tTraining loss: 0.13115\t\t Validation Loss: 1.32587\tValidation Accuracy: 0.84812\n",
      "Epoch: 66\tTraining loss: 0.13506\t\t Validation Loss: 1.36434\tValidation Accuracy: 0.84348\n",
      "Epoch: 67\tTraining loss: 0.12790\t\t Validation Loss: 1.32801\tValidation Accuracy: 0.85043\n",
      "Epoch: 68\tTraining loss: 0.12959\t\t Validation Loss: 1.32335\tValidation Accuracy: 0.84928\n",
      "Epoch: 69\tTraining loss: 0.12438\t\t Validation Loss: 1.48559\tValidation Accuracy: 0.84580\n",
      "Epoch: 70\tTraining loss: 0.12479\t\t Validation Loss: 1.55456\tValidation Accuracy: 0.86203\n",
      "Epoch: 71\tTraining loss: 0.12178\t\t Validation Loss: 1.51938\tValidation Accuracy: 0.87072\n",
      "Epoch: 72\tTraining loss: 0.11397\t\t Validation Loss: 1.46248\tValidation Accuracy: 0.85739\n",
      "Epoch: 73\tTraining loss: 0.11615\t\t Validation Loss: 1.32588\tValidation Accuracy: 0.85101\n",
      "Epoch: 74\tTraining loss: 0.10586\t\t Validation Loss: 1.61936\tValidation Accuracy: 0.86957\n",
      "Saved model successfully!\n"
     ]
    }
   ],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.device_ = device\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(0.1)\n",
    "\n",
    "        self.fc_net = nn.Sequential(\n",
    "            nn.Linear(178, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(500, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        X = X.squeeze(-1).to(self.device_)\n",
    "        X = self.dropout_1(X)\n",
    "        return self.fc_net(X)\n",
    "    \n",
    "    def predict_batch(self, X: torch.FloatTensor):\n",
    "        pred = (torch.sigmoid(self(X)) > 0.5).int()\n",
    "        return pred\n",
    "\n",
    "    def predict(self, dataloader: DataLoader):\n",
    "        predictions = list()\n",
    "        for i, data in enumerate(dataloader, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            with torch.no_grad():\n",
    "                X = data[\"X\"]\n",
    "                y_pred = self.predict_batch(X)\n",
    "                predictions.append(y_pred)\n",
    "        predictions = torch.cat(predictions, 0)\n",
    "        return predictions\n",
    "\n",
    "    def to_string(self):\n",
    "        return \"MLPClassifier\"\n",
    "    \n",
    "\n",
    "model_mlp = MLPClassifier(DEVICE)\n",
    "state_mlp = training(model_mlp, train_dataloader, val_dataloader, device=DEVICE, epochs=NUM_EPOCHS, lr=LEARNING_RATE, earlystopping_tolerance=NUM_EPOCHS)\n",
    "# model.predict_batch(X_train[:32])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN (Fully Convoluted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTraining loss: 0.74550\t\t Validation Loss: 0.56391\tValidation Accuracy: 0.84058\n",
      "Epoch: 1\tTraining loss: 0.50823\t\t Validation Loss: 0.45471\tValidation Accuracy: 0.87652\n",
      "Epoch: 2\tTraining loss: 0.42527\t\t Validation Loss: 0.40139\tValidation Accuracy: 0.88812\n",
      "Epoch: 3\tTraining loss: 0.38402\t\t Validation Loss: 0.36678\tValidation Accuracy: 0.90377\n",
      "Epoch: 4\tTraining loss: 0.36392\t\t Validation Loss: 0.35097\tValidation Accuracy: 0.91246\n",
      "Epoch: 5\tTraining loss: 0.32596\t\t Validation Loss: 0.31449\tValidation Accuracy: 0.92116\n",
      "Epoch: 6\tTraining loss: 0.32539\t\t Validation Loss: 0.33061\tValidation Accuracy: 0.92000\n",
      "Epoch: 7\tTraining loss: 0.30213\t\t Validation Loss: 0.30161\tValidation Accuracy: 0.92174\n",
      "Epoch: 8\tTraining loss: 0.29620\t\t Validation Loss: 0.31689\tValidation Accuracy: 0.92986\n",
      "Epoch: 9\tTraining loss: 0.28595\t\t Validation Loss: 0.27912\tValidation Accuracy: 0.92464\n",
      "Epoch: 10\tTraining loss: 0.26517\t\t Validation Loss: 0.33102\tValidation Accuracy: 0.94667\n",
      "Epoch: 11\tTraining loss: 0.27793\t\t Validation Loss: 0.30253\tValidation Accuracy: 0.92522\n",
      "Epoch: 12\tTraining loss: 0.26808\t\t Validation Loss: 0.27309\tValidation Accuracy: 0.93391\n",
      "Epoch: 13\tTraining loss: 0.25191\t\t Validation Loss: 0.25271\tValidation Accuracy: 0.93391\n",
      "Epoch: 14\tTraining loss: 0.24626\t\t Validation Loss: 0.26177\tValidation Accuracy: 0.93101\n",
      "Epoch: 15\tTraining loss: 0.23940\t\t Validation Loss: 0.24466\tValidation Accuracy: 0.95188\n",
      "Epoch: 16\tTraining loss: 0.24025\t\t Validation Loss: 0.25131\tValidation Accuracy: 0.94087\n",
      "Epoch: 17\tTraining loss: 0.23043\t\t Validation Loss: 0.25245\tValidation Accuracy: 0.93449\n",
      "Epoch: 18\tTraining loss: 0.22776\t\t Validation Loss: 0.23348\tValidation Accuracy: 0.93971\n",
      "Epoch: 19\tTraining loss: 0.22312\t\t Validation Loss: 0.23341\tValidation Accuracy: 0.93855\n",
      "Epoch: 20\tTraining loss: 0.22931\t\t Validation Loss: 0.24379\tValidation Accuracy: 0.95304\n",
      "Epoch: 21\tTraining loss: 0.22667\t\t Validation Loss: 0.23673\tValidation Accuracy: 0.93797\n",
      "Epoch: 22\tTraining loss: 0.22500\t\t Validation Loss: 0.23421\tValidation Accuracy: 0.94667\n",
      "Epoch: 23\tTraining loss: 0.21222\t\t Validation Loss: 0.23450\tValidation Accuracy: 0.94841\n",
      "Epoch: 24\tTraining loss: 0.21189\t\t Validation Loss: 0.24413\tValidation Accuracy: 0.93275\n",
      "Epoch: 25\tTraining loss: 0.20925\t\t Validation Loss: 0.21881\tValidation Accuracy: 0.95420\n",
      "Epoch: 26\tTraining loss: 0.21233\t\t Validation Loss: 0.22134\tValidation Accuracy: 0.95072\n",
      "Epoch: 27\tTraining loss: 0.19937\t\t Validation Loss: 0.23439\tValidation Accuracy: 0.94087\n",
      "Epoch: 28\tTraining loss: 0.20254\t\t Validation Loss: 0.24211\tValidation Accuracy: 0.96000\n",
      "Epoch: 29\tTraining loss: 0.20926\t\t Validation Loss: 0.22992\tValidation Accuracy: 0.95478\n",
      "Epoch: 30\tTraining loss: 0.20869\t\t Validation Loss: 0.24643\tValidation Accuracy: 0.93217\n",
      "Epoch: 31\tTraining loss: 0.19227\t\t Validation Loss: 0.22522\tValidation Accuracy: 0.94261\n",
      "Epoch: 32\tTraining loss: 0.19419\t\t Validation Loss: 0.20067\tValidation Accuracy: 0.95304\n",
      "Epoch: 33\tTraining loss: 0.20336\t\t Validation Loss: 0.24576\tValidation Accuracy: 0.95304\n",
      "Epoch: 34\tTraining loss: 0.19241\t\t Validation Loss: 0.22206\tValidation Accuracy: 0.95710\n",
      "Epoch: 35\tTraining loss: 0.19282\t\t Validation Loss: 0.22251\tValidation Accuracy: 0.95246\n",
      "Epoch: 36\tTraining loss: 0.18596\t\t Validation Loss: 0.20884\tValidation Accuracy: 0.95246\n",
      "Epoch: 37\tTraining loss: 0.18748\t\t Validation Loss: 0.19770\tValidation Accuracy: 0.95072\n",
      "Epoch: 38\tTraining loss: 0.19117\t\t Validation Loss: 0.20876\tValidation Accuracy: 0.95130\n",
      "Epoch: 39\tTraining loss: 0.19365\t\t Validation Loss: 0.23168\tValidation Accuracy: 0.95420\n",
      "Epoch: 40\tTraining loss: 0.18685\t\t Validation Loss: 0.21538\tValidation Accuracy: 0.96116\n",
      "Epoch: 41\tTraining loss: 0.17770\t\t Validation Loss: 0.21890\tValidation Accuracy: 0.96000\n",
      "Epoch: 42\tTraining loss: 0.18194\t\t Validation Loss: 0.20139\tValidation Accuracy: 0.96000\n",
      "Epoch: 43\tTraining loss: 0.16582\t\t Validation Loss: 0.20489\tValidation Accuracy: 0.94957\n",
      "Epoch: 44\tTraining loss: 0.18199\t\t Validation Loss: 0.19267\tValidation Accuracy: 0.96000\n",
      "Epoch: 45\tTraining loss: 0.17782\t\t Validation Loss: 0.19304\tValidation Accuracy: 0.96116\n",
      "Epoch: 46\tTraining loss: 0.17139\t\t Validation Loss: 0.20145\tValidation Accuracy: 0.96406\n",
      "Epoch: 47\tTraining loss: 0.17142\t\t Validation Loss: 0.19550\tValidation Accuracy: 0.95536\n",
      "Epoch: 48\tTraining loss: 0.17335\t\t Validation Loss: 0.20150\tValidation Accuracy: 0.95304\n",
      "Epoch: 49\tTraining loss: 0.16900\t\t Validation Loss: 0.18782\tValidation Accuracy: 0.96058\n",
      "Epoch: 50\tTraining loss: 0.16826\t\t Validation Loss: 0.20929\tValidation Accuracy: 0.95420\n",
      "Epoch: 51\tTraining loss: 0.16300\t\t Validation Loss: 0.18578\tValidation Accuracy: 0.96000\n",
      "Epoch: 52\tTraining loss: 0.16756\t\t Validation Loss: 0.18882\tValidation Accuracy: 0.96638\n",
      "Epoch: 53\tTraining loss: 0.16657\t\t Validation Loss: 0.21169\tValidation Accuracy: 0.94609\n",
      "Epoch: 54\tTraining loss: 0.16869\t\t Validation Loss: 0.18832\tValidation Accuracy: 0.95362\n",
      "Epoch: 55\tTraining loss: 0.16992\t\t Validation Loss: 0.20216\tValidation Accuracy: 0.96232\n",
      "Epoch: 56\tTraining loss: 0.15461\t\t Validation Loss: 0.19439\tValidation Accuracy: 0.95884\n",
      "Epoch: 57\tTraining loss: 0.16352\t\t Validation Loss: 0.21241\tValidation Accuracy: 0.95072\n",
      "Epoch: 58\tTraining loss: 0.16001\t\t Validation Loss: 0.20674\tValidation Accuracy: 0.95420\n",
      "Epoch: 59\tTraining loss: 0.16289\t\t Validation Loss: 0.18888\tValidation Accuracy: 0.96522\n",
      "Epoch: 60\tTraining loss: 0.16215\t\t Validation Loss: 0.20849\tValidation Accuracy: 0.95826\n",
      "Epoch: 61\tTraining loss: 0.15400\t\t Validation Loss: 0.21278\tValidation Accuracy: 0.95884\n",
      "Epoch: 62\tTraining loss: 0.15705\t\t Validation Loss: 0.18551\tValidation Accuracy: 0.96116\n",
      "Epoch: 63\tTraining loss: 0.15882\t\t Validation Loss: 0.21024\tValidation Accuracy: 0.95942\n",
      "Epoch: 64\tTraining loss: 0.15486\t\t Validation Loss: 0.20226\tValidation Accuracy: 0.94899\n",
      "Epoch: 65\tTraining loss: 0.14506\t\t Validation Loss: 0.17469\tValidation Accuracy: 0.96638\n",
      "Epoch: 66\tTraining loss: 0.14813\t\t Validation Loss: 0.19947\tValidation Accuracy: 0.95942\n",
      "Epoch: 67\tTraining loss: 0.14560\t\t Validation Loss: 0.19309\tValidation Accuracy: 0.94609\n",
      "Epoch: 68\tTraining loss: 0.15336\t\t Validation Loss: 0.18513\tValidation Accuracy: 0.95710\n",
      "Epoch: 69\tTraining loss: 0.14874\t\t Validation Loss: 0.19284\tValidation Accuracy: 0.95768\n",
      "Epoch: 70\tTraining loss: 0.15537\t\t Validation Loss: 0.17777\tValidation Accuracy: 0.96754\n",
      "Epoch: 71\tTraining loss: 0.15086\t\t Validation Loss: 0.18036\tValidation Accuracy: 0.95826\n",
      "Epoch: 72\tTraining loss: 0.15543\t\t Validation Loss: 0.19093\tValidation Accuracy: 0.96058\n",
      "Epoch: 73\tTraining loss: 0.14958\t\t Validation Loss: 0.19077\tValidation Accuracy: 0.95594\n",
      "Epoch: 74\tTraining loss: 0.15261\t\t Validation Loss: 0.18881\tValidation Accuracy: 0.96696\n",
      "Saved model successfully!\n"
     ]
    }
   ],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.device_ = device\n",
    "\n",
    "        self.conv_fc = nn.Sequential(\n",
    "            nn.Conv1d(1, 128, 3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, 3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 128, 3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.transpose(-1, -2).to(self.device_)\n",
    "        conv = self.conv_fc(X)\n",
    "        return conv\n",
    "    \n",
    "    def predict_batch(self, X: torch.FloatTensor):\n",
    "        pred = (torch.sigmoid(self(X)) > 0.5).int()\n",
    "        return pred\n",
    "\n",
    "    def predict(self, dataloader: DataLoader):\n",
    "        predictions = list()\n",
    "        for i, data in enumerate(dataloader, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            with torch.no_grad():\n",
    "                X = data[\"X\"]\n",
    "                y_pred = self.predict_batch(X)\n",
    "                predictions.append(y_pred)\n",
    "        predictions = torch.cat(predictions, 0)\n",
    "        return predictions\n",
    "\n",
    "    def to_string(self):\n",
    "        return \"FCN\"\n",
    "    \n",
    "\n",
    "model_fcn = FCN(DEVICE)\n",
    "state_fcn = training(model_fcn, train_dataloader, val_dataloader, device=DEVICE, epochs=NUM_EPOCHS, lr=LEARNING_RATE, earlystopping_tolerance=NUM_EPOCHS)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.device_ = device\n",
    "\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.transpose(-1, -2).to(self.device_)\n",
    "        conv = self.conv_block_1(X)\n",
    "        return conv\n",
    "    \n",
    "\n",
    "# model = ResNet()\n",
    "# state = training(model, train_dataloader, val_dataloader, device=DEVICE, epochs=10, lr=1e-4, earlystopping_tolerance=10)\n",
    "\n",
    "# model(X_train[:32]).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTraining loss: 1.11780\t\t Validation Loss: 1.11590\tValidation Accuracy: 0.20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulo\\Anaconda3\\envs\\inf8225\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tTraining loss: 1.11184\t\t Validation Loss: 1.11629\tValidation Accuracy: 0.80000\n",
      "Epoch: 2\tTraining loss: 1.10912\t\t Validation Loss: 1.08464\tValidation Accuracy: 0.43884\n",
      "Epoch: 3\tTraining loss: 0.88967\t\t Validation Loss: 0.74350\tValidation Accuracy: 0.83478\n",
      "Epoch: 4\tTraining loss: 0.70538\t\t Validation Loss: 0.69571\tValidation Accuracy: 0.82493\n",
      "Epoch: 5\tTraining loss: 0.62042\t\t Validation Loss: 0.68383\tValidation Accuracy: 0.82783\n",
      "Epoch: 6\tTraining loss: 0.55493\t\t Validation Loss: 0.68053\tValidation Accuracy: 0.87304\n",
      "Epoch: 7\tTraining loss: 0.48433\t\t Validation Loss: 0.66636\tValidation Accuracy: 0.85043\n",
      "Epoch: 8\tTraining loss: 0.43918\t\t Validation Loss: 0.70504\tValidation Accuracy: 0.88116\n",
      "Epoch: 9\tTraining loss: 0.37736\t\t Validation Loss: 0.66210\tValidation Accuracy: 0.85101\n",
      "Epoch: 10\tTraining loss: 0.31059\t\t Validation Loss: 0.81869\tValidation Accuracy: 0.87478\n",
      "Epoch: 11\tTraining loss: 0.26969\t\t Validation Loss: 0.71408\tValidation Accuracy: 0.85391\n",
      "Epoch: 12\tTraining loss: 0.21788\t\t Validation Loss: 0.80824\tValidation Accuracy: 0.84638\n",
      "Epoch: 13\tTraining loss: 0.18430\t\t Validation Loss: 0.86578\tValidation Accuracy: 0.85101\n",
      "Epoch: 14\tTraining loss: 0.15200\t\t Validation Loss: 0.85621\tValidation Accuracy: 0.86899\n",
      "Epoch: 15\tTraining loss: 0.12723\t\t Validation Loss: 0.90134\tValidation Accuracy: 0.86319\n",
      "Epoch: 16\tTraining loss: 0.10006\t\t Validation Loss: 0.96550\tValidation Accuracy: 0.86087\n",
      "Epoch: 17\tTraining loss: 0.07911\t\t Validation Loss: 0.94192\tValidation Accuracy: 0.86957\n",
      "Epoch: 18\tTraining loss: 0.08323\t\t Validation Loss: 1.05764\tValidation Accuracy: 0.86435\n",
      "Epoch: 19\tTraining loss: 0.05951\t\t Validation Loss: 1.11713\tValidation Accuracy: 0.86319\n",
      "Epoch: 20\tTraining loss: 0.05771\t\t Validation Loss: 1.11083\tValidation Accuracy: 0.87652\n",
      "Epoch: 21\tTraining loss: 0.04823\t\t Validation Loss: 1.03046\tValidation Accuracy: 0.86783\n",
      "Epoch: 22\tTraining loss: 0.03426\t\t Validation Loss: 1.09452\tValidation Accuracy: 0.87536\n",
      "Epoch: 23\tTraining loss: 0.05050\t\t Validation Loss: 1.06279\tValidation Accuracy: 0.81797\n",
      "Epoch: 24\tTraining loss: 0.04823\t\t Validation Loss: 1.19545\tValidation Accuracy: 0.87768\n",
      "Epoch: 25\tTraining loss: 0.01694\t\t Validation Loss: 1.16126\tValidation Accuracy: 0.88406\n",
      "Epoch: 26\tTraining loss: 0.01977\t\t Validation Loss: 1.30573\tValidation Accuracy: 0.87942\n",
      "Epoch: 27\tTraining loss: 0.04599\t\t Validation Loss: 1.25614\tValidation Accuracy: 0.88696\n",
      "Epoch: 28\tTraining loss: 0.05388\t\t Validation Loss: 1.33894\tValidation Accuracy: 0.87652\n",
      "Epoch: 29\tTraining loss: 0.06002\t\t Validation Loss: 1.19832\tValidation Accuracy: 0.87130\n",
      "Epoch: 30\tTraining loss: 0.02785\t\t Validation Loss: 1.65188\tValidation Accuracy: 0.88290\n",
      "Epoch: 31\tTraining loss: 0.01931\t\t Validation Loss: 1.36287\tValidation Accuracy: 0.88348\n",
      "Epoch: 32\tTraining loss: 0.00546\t\t Validation Loss: 1.44885\tValidation Accuracy: 0.88290\n",
      "Epoch: 33\tTraining loss: 0.00331\t\t Validation Loss: 1.41958\tValidation Accuracy: 0.88754\n",
      "Epoch: 34\tTraining loss: 0.00220\t\t Validation Loss: 1.57504\tValidation Accuracy: 0.88870\n",
      "Epoch: 35\tTraining loss: 0.00238\t\t Validation Loss: 1.61895\tValidation Accuracy: 0.88696\n",
      "Epoch: 36\tTraining loss: 0.00527\t\t Validation Loss: 1.69555\tValidation Accuracy: 0.88812\n",
      "Epoch: 37\tTraining loss: 0.09760\t\t Validation Loss: 1.31566\tValidation Accuracy: 0.77449\n",
      "Epoch: 38\tTraining loss: 0.07994\t\t Validation Loss: 1.28417\tValidation Accuracy: 0.87884\n",
      "Epoch: 39\tTraining loss: 0.02136\t\t Validation Loss: 1.28583\tValidation Accuracy: 0.88522\n",
      "Epoch: 40\tTraining loss: 0.00754\t\t Validation Loss: 1.37647\tValidation Accuracy: 0.88986\n",
      "Epoch: 41\tTraining loss: 0.00406\t\t Validation Loss: 1.34763\tValidation Accuracy: 0.88928\n",
      "Epoch: 42\tTraining loss: 0.00316\t\t Validation Loss: 1.35495\tValidation Accuracy: 0.88464\n",
      "Epoch: 43\tTraining loss: 0.00214\t\t Validation Loss: 1.45028\tValidation Accuracy: 0.88522\n",
      "Epoch: 44\tTraining loss: 0.00147\t\t Validation Loss: 1.60688\tValidation Accuracy: 0.88580\n",
      "Epoch: 45\tTraining loss: 0.00118\t\t Validation Loss: 1.52319\tValidation Accuracy: 0.88986\n",
      "Epoch: 46\tTraining loss: 0.00093\t\t Validation Loss: 1.56078\tValidation Accuracy: 0.88232\n",
      "Epoch: 47\tTraining loss: 0.00102\t\t Validation Loss: 1.50079\tValidation Accuracy: 0.88986\n",
      "Epoch: 48\tTraining loss: 0.00089\t\t Validation Loss: 1.64108\tValidation Accuracy: 0.89043\n",
      "Epoch: 49\tTraining loss: 0.00065\t\t Validation Loss: 1.59701\tValidation Accuracy: 0.89217\n",
      "Epoch: 50\tTraining loss: 0.00061\t\t Validation Loss: 1.67193\tValidation Accuracy: 0.88696\n",
      "Epoch: 51\tTraining loss: 0.00049\t\t Validation Loss: 1.71151\tValidation Accuracy: 0.88580\n",
      "Epoch: 52\tTraining loss: 0.00042\t\t Validation Loss: 1.71753\tValidation Accuracy: 0.88754\n",
      "Epoch: 53\tTraining loss: 0.00032\t\t Validation Loss: 1.74741\tValidation Accuracy: 0.88696\n",
      "Epoch: 54\tTraining loss: 0.00034\t\t Validation Loss: 1.79906\tValidation Accuracy: 0.88754\n",
      "Epoch: 55\tTraining loss: 0.00031\t\t Validation Loss: 1.71873\tValidation Accuracy: 0.88638\n",
      "Epoch: 56\tTraining loss: 0.00034\t\t Validation Loss: 1.75867\tValidation Accuracy: 0.88754\n",
      "Epoch: 57\tTraining loss: 0.00020\t\t Validation Loss: 1.92026\tValidation Accuracy: 0.88986\n",
      "Epoch: 58\tTraining loss: 0.00017\t\t Validation Loss: 1.92710\tValidation Accuracy: 0.89275\n",
      "Epoch: 59\tTraining loss: 0.18608\t\t Validation Loss: 1.14154\tValidation Accuracy: 0.86319\n",
      "Epoch: 60\tTraining loss: 0.08577\t\t Validation Loss: 1.34548\tValidation Accuracy: 0.88812\n",
      "Epoch: 61\tTraining loss: 0.02575\t\t Validation Loss: 1.49149\tValidation Accuracy: 0.86145\n",
      "Epoch: 62\tTraining loss: 0.01063\t\t Validation Loss: 1.65423\tValidation Accuracy: 0.88522\n",
      "Epoch: 63\tTraining loss: 0.00739\t\t Validation Loss: 1.59609\tValidation Accuracy: 0.86725\n",
      "Epoch: 64\tTraining loss: 0.00517\t\t Validation Loss: 1.60052\tValidation Accuracy: 0.88696\n",
      "Epoch: 65\tTraining loss: 0.00256\t\t Validation Loss: 1.67003\tValidation Accuracy: 0.88116\n",
      "Epoch: 66\tTraining loss: 0.01159\t\t Validation Loss: 1.79513\tValidation Accuracy: 0.87420\n",
      "Epoch: 67\tTraining loss: 0.04781\t\t Validation Loss: 1.46415\tValidation Accuracy: 0.85971\n",
      "Epoch: 68\tTraining loss: 0.02208\t\t Validation Loss: 1.48938\tValidation Accuracy: 0.86319\n",
      "Epoch: 69\tTraining loss: 0.00834\t\t Validation Loss: 1.78284\tValidation Accuracy: 0.87478\n",
      "Epoch: 70\tTraining loss: 0.00221\t\t Validation Loss: 1.67582\tValidation Accuracy: 0.88812\n",
      "Epoch: 71\tTraining loss: 0.00107\t\t Validation Loss: 1.65340\tValidation Accuracy: 0.88522\n",
      "Epoch: 72\tTraining loss: 0.00092\t\t Validation Loss: 1.77516\tValidation Accuracy: 0.88464\n",
      "Epoch: 73\tTraining loss: 0.00068\t\t Validation Loss: 1.84766\tValidation Accuracy: 0.89391\n",
      "Epoch: 74\tTraining loss: 0.00106\t\t Validation Loss: 1.76123\tValidation Accuracy: 0.88812\n",
      "Saved model successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class TransformerUnsupervised(nn.Module):\n",
    "    def __init__(self, device: str = \"cpu\", supervised: bool = False, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.device_ = device\n",
    "        self.supervised = supervised\n",
    "        self.unsupervised_training = False\n",
    "        self.d_model = 512\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.projection = nn.Linear(1, self.d_model)\n",
    "\n",
    "        self.pos_embedding = PositionalEncoding(d_model=self.d_model, dropout=dropout, max_len=1024)\n",
    "\n",
    "        self.enc_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=8, dim_feedforward=2048, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.enc_layer,\n",
    "            num_layers=2,    \n",
    "        )\n",
    "\n",
    "        self.linearization = nn.Linear(self.d_model*178, 178)\n",
    "\n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Linear(self.d_model*178, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        # X = X.transpose(0, 1)\n",
    "        # print(X.shape)\n",
    "        out = self.dropout1(torch.tanh(self.projection(X)))\n",
    "        out = self.pos_embedding(out)\n",
    "\n",
    "        out = self.dropout2(out)\n",
    "        out = self.transformer_encoder(out)\n",
    "        \n",
    "        out = out.view(-1, self.d_model*X.shape[1])\n",
    "        out = self.dropout3(out)\n",
    "\n",
    "        if self.supervised:\n",
    "            out = self.fc_out(out)\n",
    "        else:\n",
    "            out = self.linearization(out).squeeze(-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def predict_batch(self, X: torch.FloatTensor):\n",
    "        pred = (torch.sigmoid(self(X)) > 0.5).int()\n",
    "        return pred\n",
    "    \n",
    "    def predict(self, dataloader: DataLoader):\n",
    "        predictions = list()\n",
    "        for i, data in enumerate(dataloader, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            with torch.no_grad():\n",
    "                X = data[\"X\"]\n",
    "                y_pred = self.predict_batch(X)\n",
    "                predictions.append(y_pred)\n",
    "        predictions = torch.cat(predictions, 0)\n",
    "        return predictions\n",
    "\n",
    "    def to_string(self):\n",
    "        return f\"TransformerUnsupervised_{self.unsupervised_training}\"\n",
    "    \n",
    "\n",
    "\n",
    "model_transformer_supervided = TransformerUnsupervised(supervised=True, dropout=0.25)\n",
    "state_transformer_supervided = training(model_transformer_supervided, train_dataloader, val_dataloader, device=DEVICE, epochs=NUM_EPOCHS, lr=LEARNING_RATE, earlystopping_tolerance=NUM_EPOCHS)\n",
    "# print(X_train[:32].shape)\n",
    "# model(X_train[:32]).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTraining loss: 21.34767\n",
      "Epoch: 1\tTraining loss: 0.69984\n",
      "Epoch: 2\tTraining loss: 0.49293\n",
      "Epoch: 3\tTraining loss: 0.62964\n",
      "Epoch: 4\tTraining loss: 0.57151\n",
      "Epoch: 5\tTraining loss: 0.60441\n",
      "Epoch: 6\tTraining loss: 0.45536\n",
      "Epoch: 7\tTraining loss: 0.35912\n",
      "Epoch: 8\tTraining loss: 0.26775\n",
      "Epoch: 9\tTraining loss: 0.20668\n",
      "Epoch: 10\tTraining loss: 0.21424\n",
      "Epoch: 11\tTraining loss: 0.13202\n",
      "Epoch: 12\tTraining loss: 0.10894\n",
      "Epoch: 13\tTraining loss: 0.08259\n",
      "Epoch: 14\tTraining loss: 0.06922\n",
      "Epoch: 15\tTraining loss: 0.05788\n",
      "Epoch: 16\tTraining loss: 0.05321\n",
      "Epoch: 17\tTraining loss: 0.04866\n",
      "Epoch: 18\tTraining loss: 0.04574\n",
      "Epoch: 19\tTraining loss: 0.04044\n",
      "Epoch: 20\tTraining loss: 0.03582\n",
      "Epoch: 21\tTraining loss: 0.02896\n",
      "Epoch: 22\tTraining loss: 0.01972\n",
      "Epoch: 23\tTraining loss: 0.01463\n",
      "Epoch: 24\tTraining loss: 0.01281\n",
      "Epoch: 25\tTraining loss: 0.01194\n",
      "Epoch: 26\tTraining loss: 0.01064\n",
      "Epoch: 27\tTraining loss: 0.01033\n",
      "Epoch: 28\tTraining loss: 0.00985\n",
      "Epoch: 29\tTraining loss: 0.00921\n",
      "Unsupervised training has ended!\n",
      "Epoch: 0\tTraining loss: 0.87000\t\t Validation Loss: 0.74425\tValidation Accuracy: 0.80290\n",
      "Epoch: 1\tTraining loss: 0.65712\t\t Validation Loss: 0.61914\tValidation Accuracy: 0.83652\n",
      "Epoch: 2\tTraining loss: 0.55098\t\t Validation Loss: 0.62340\tValidation Accuracy: 0.83710\n",
      "Epoch: 3\tTraining loss: 0.44966\t\t Validation Loss: 0.60247\tValidation Accuracy: 0.86841\n",
      "Epoch: 4\tTraining loss: 0.37252\t\t Validation Loss: 0.60059\tValidation Accuracy: 0.81043\n",
      "Epoch: 5\tTraining loss: 0.29143\t\t Validation Loss: 0.63262\tValidation Accuracy: 0.89565\n",
      "Epoch: 6\tTraining loss: 0.23540\t\t Validation Loss: 0.55480\tValidation Accuracy: 0.87652\n",
      "Epoch: 7\tTraining loss: 0.18114\t\t Validation Loss: 0.71221\tValidation Accuracy: 0.90667\n",
      "Epoch: 8\tTraining loss: 0.15041\t\t Validation Loss: 0.59519\tValidation Accuracy: 0.87478\n",
      "Epoch: 9\tTraining loss: 0.11887\t\t Validation Loss: 0.66995\tValidation Accuracy: 0.88696\n",
      "Epoch: 10\tTraining loss: 0.10517\t\t Validation Loss: 0.74550\tValidation Accuracy: 0.90551\n",
      "Epoch: 11\tTraining loss: 0.09330\t\t Validation Loss: 0.81870\tValidation Accuracy: 0.90609\n",
      "Epoch: 12\tTraining loss: 0.07773\t\t Validation Loss: 0.73818\tValidation Accuracy: 0.89449\n",
      "Epoch: 13\tTraining loss: 0.06455\t\t Validation Loss: 0.79164\tValidation Accuracy: 0.90319\n",
      "Epoch: 14\tTraining loss: 0.05568\t\t Validation Loss: 0.86482\tValidation Accuracy: 0.90841\n",
      "Epoch: 15\tTraining loss: 0.04692\t\t Validation Loss: 0.79550\tValidation Accuracy: 0.90319\n",
      "Epoch: 16\tTraining loss: 0.02582\t\t Validation Loss: 0.84404\tValidation Accuracy: 0.91072\n",
      "Epoch: 17\tTraining loss: 0.03640\t\t Validation Loss: 0.85316\tValidation Accuracy: 0.89449\n",
      "Epoch: 18\tTraining loss: 0.04978\t\t Validation Loss: 0.83601\tValidation Accuracy: 0.89971\n",
      "Epoch: 19\tTraining loss: 0.02861\t\t Validation Loss: 0.91494\tValidation Accuracy: 0.87072\n",
      "Epoch: 20\tTraining loss: 0.05753\t\t Validation Loss: 0.71697\tValidation Accuracy: 0.89275\n",
      "Epoch: 21\tTraining loss: 0.07567\t\t Validation Loss: 0.97674\tValidation Accuracy: 0.90841\n",
      "Epoch: 22\tTraining loss: 0.03517\t\t Validation Loss: 0.90003\tValidation Accuracy: 0.90551\n",
      "Epoch: 23\tTraining loss: 0.02053\t\t Validation Loss: 1.04682\tValidation Accuracy: 0.90667\n",
      "Epoch: 24\tTraining loss: 0.00484\t\t Validation Loss: 0.96004\tValidation Accuracy: 0.91188\n",
      "Epoch: 25\tTraining loss: 0.00437\t\t Validation Loss: 1.04650\tValidation Accuracy: 0.91536\n",
      "Epoch: 26\tTraining loss: 0.00176\t\t Validation Loss: 1.06899\tValidation Accuracy: 0.91478\n",
      "Epoch: 27\tTraining loss: 0.00220\t\t Validation Loss: 1.05190\tValidation Accuracy: 0.92000\n",
      "Epoch: 28\tTraining loss: 0.00112\t\t Validation Loss: 1.07269\tValidation Accuracy: 0.91536\n",
      "Epoch: 29\tTraining loss: 0.00116\t\t Validation Loss: 1.04347\tValidation Accuracy: 0.91710\n",
      "Epoch: 30\tTraining loss: 0.09987\t\t Validation Loss: 0.94269\tValidation Accuracy: 0.87420\n",
      "Epoch: 31\tTraining loss: 0.11975\t\t Validation Loss: 0.88571\tValidation Accuracy: 0.89507\n",
      "Epoch: 32\tTraining loss: 0.03127\t\t Validation Loss: 1.12365\tValidation Accuracy: 0.89855\n",
      "Epoch: 33\tTraining loss: 0.01974\t\t Validation Loss: 1.03559\tValidation Accuracy: 0.88986\n",
      "Epoch: 34\tTraining loss: 0.01579\t\t Validation Loss: 1.14681\tValidation Accuracy: 0.89797\n",
      "Epoch: 35\tTraining loss: 0.02489\t\t Validation Loss: 0.94657\tValidation Accuracy: 0.90493\n",
      "Epoch: 36\tTraining loss: 0.00999\t\t Validation Loss: 0.99328\tValidation Accuracy: 0.89159\n",
      "Epoch: 37\tTraining loss: 0.04335\t\t Validation Loss: 0.90697\tValidation Accuracy: 0.89043\n",
      "Epoch: 38\tTraining loss: 0.06098\t\t Validation Loss: 0.97022\tValidation Accuracy: 0.90203\n",
      "Epoch: 39\tTraining loss: 0.00829\t\t Validation Loss: 1.06455\tValidation Accuracy: 0.89971\n",
      "Epoch: 40\tTraining loss: 0.00962\t\t Validation Loss: 0.95477\tValidation Accuracy: 0.89333\n",
      "Epoch: 41\tTraining loss: 0.00753\t\t Validation Loss: 1.38554\tValidation Accuracy: 0.90783\n",
      "Epoch: 42\tTraining loss: 0.00465\t\t Validation Loss: 1.13684\tValidation Accuracy: 0.91188\n",
      "Epoch: 43\tTraining loss: 0.02886\t\t Validation Loss: 1.05809\tValidation Accuracy: 0.85391\n",
      "Epoch: 44\tTraining loss: 0.04806\t\t Validation Loss: 1.10571\tValidation Accuracy: 0.90493\n",
      "Epoch: 45\tTraining loss: 0.02532\t\t Validation Loss: 1.29353\tValidation Accuracy: 0.89333\n",
      "Epoch: 46\tTraining loss: 0.01715\t\t Validation Loss: 1.25064\tValidation Accuracy: 0.90551\n",
      "Epoch: 47\tTraining loss: 0.00288\t\t Validation Loss: 1.27283\tValidation Accuracy: 0.90725\n",
      "Epoch: 48\tTraining loss: 0.00101\t\t Validation Loss: 1.27862\tValidation Accuracy: 0.90899\n",
      "Epoch: 49\tTraining loss: 0.00067\t\t Validation Loss: 1.28099\tValidation Accuracy: 0.91536\n",
      "Epoch: 50\tTraining loss: 0.00058\t\t Validation Loss: 1.31577\tValidation Accuracy: 0.90899\n",
      "Epoch: 51\tTraining loss: 0.00051\t\t Validation Loss: 1.27513\tValidation Accuracy: 0.91478\n",
      "Epoch: 52\tTraining loss: 0.00039\t\t Validation Loss: 1.35021\tValidation Accuracy: 0.91594\n",
      "Epoch: 53\tTraining loss: 0.00033\t\t Validation Loss: 1.33432\tValidation Accuracy: 0.91362\n",
      "Epoch: 54\tTraining loss: 0.00030\t\t Validation Loss: 1.47839\tValidation Accuracy: 0.91246\n",
      "Epoch: 55\tTraining loss: 0.09743\t\t Validation Loss: 0.87254\tValidation Accuracy: 0.88928\n",
      "Epoch: 56\tTraining loss: 0.03779\t\t Validation Loss: 1.00079\tValidation Accuracy: 0.89739\n",
      "Epoch: 57\tTraining loss: 0.01674\t\t Validation Loss: 1.06315\tValidation Accuracy: 0.89681\n",
      "Epoch: 58\tTraining loss: 0.00468\t\t Validation Loss: 1.28649\tValidation Accuracy: 0.91130\n",
      "Epoch: 59\tTraining loss: 0.00127\t\t Validation Loss: 1.27456\tValidation Accuracy: 0.90667\n",
      "Epoch: 60\tTraining loss: 0.00081\t\t Validation Loss: 1.29416\tValidation Accuracy: 0.91304\n",
      "Epoch: 61\tTraining loss: 0.00066\t\t Validation Loss: 1.37692\tValidation Accuracy: 0.91130\n",
      "Epoch: 62\tTraining loss: 0.00058\t\t Validation Loss: 1.28763\tValidation Accuracy: 0.91420\n",
      "Epoch: 63\tTraining loss: 0.00043\t\t Validation Loss: 1.43788\tValidation Accuracy: 0.91304\n",
      "Epoch: 64\tTraining loss: 0.00027\t\t Validation Loss: 1.32899\tValidation Accuracy: 0.92000\n",
      "Epoch: 65\tTraining loss: 0.00031\t\t Validation Loss: 1.35218\tValidation Accuracy: 0.91304\n",
      "Epoch: 66\tTraining loss: 0.00021\t\t Validation Loss: 1.45817\tValidation Accuracy: 0.91478\n",
      "Epoch: 67\tTraining loss: 0.00021\t\t Validation Loss: 1.42111\tValidation Accuracy: 0.91188\n",
      "Epoch: 68\tTraining loss: 0.00016\t\t Validation Loss: 1.44089\tValidation Accuracy: 0.91536\n",
      "Epoch: 69\tTraining loss: 0.00015\t\t Validation Loss: 1.51312\tValidation Accuracy: 0.91536\n",
      "Epoch: 70\tTraining loss: 0.00012\t\t Validation Loss: 1.45147\tValidation Accuracy: 0.91710\n",
      "Epoch: 71\tTraining loss: 0.00011\t\t Validation Loss: 1.51246\tValidation Accuracy: 0.91594\n",
      "Epoch: 72\tTraining loss: 0.00010\t\t Validation Loss: 1.58941\tValidation Accuracy: 0.91246\n",
      "Epoch: 73\tTraining loss: 0.00009\t\t Validation Loss: 1.47791\tValidation Accuracy: 0.91652\n",
      "Epoch: 74\tTraining loss: 0.00008\t\t Validation Loss: 1.52282\tValidation Accuracy: 0.91188\n",
      "Saved model successfully!\n"
     ]
    }
   ],
   "source": [
    "def unsupervised_training(model, train_dataloader, device=DEVICE, max_epochs=100, lr=1e-5):\n",
    "    model = model.to(device)\n",
    "    model.supervised = False\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        training_loss = 0\n",
    "        for i, data in enumerate(train_dataloader, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            X = data[\"X\"].to(device)\n",
    "            X_true = X.squeeze(-1)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            X_pred = model(X)\n",
    "            train_loss = criterion(X_pred, X_true)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            training_loss += train_loss.item()\n",
    "        \n",
    "        training_loss /= i\n",
    "        print(f\"Epoch: {epoch}\\tTraining loss: {training_loss:.5f}\")\n",
    "    print(\"Unsupervised training has ended!\")    \n",
    "    torch.cuda.empty_cache()\n",
    "    return model\n",
    "\n",
    "model_transformer_unsupervided = TransformerUnsupervised(device=DEVICE, supervised=False, dropout=0.2)\n",
    "model_transformer_unsupervided = unsupervised_training(model_transformer_unsupervided, train_dataloader, DEVICE, max_epochs=30, lr=1e-3)\n",
    "model_transformer_unsupervided.supervised = True\n",
    "model_transformer_unsupervided.unsupervised_training = True\n",
    "state_model = training(model_transformer_unsupervided, train_dataloader, val_dataloader, device=DEVICE, epochs=NUM_EPOCHS, lr=LEARNING_RATE, earlystopping_tolerance=NUM_EPOCHS)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Only Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTraining loss: 1.11371\t\t Validation Loss: 1.10571\tValidation Accuracy: 0.40174\n",
      "Epoch: 1\tTraining loss: 1.10515\t\t Validation Loss: 1.10001\tValidation Accuracy: 0.32406\n",
      "Epoch: 2\tTraining loss: 1.09326\t\t Validation Loss: 1.05466\tValidation Accuracy: 0.57275\n",
      "Epoch: 3\tTraining loss: 1.02230\t\t Validation Loss: 0.97819\tValidation Accuracy: 0.64174\n",
      "Epoch: 4\tTraining loss: 0.87621\t\t Validation Loss: 0.82520\tValidation Accuracy: 0.84116\n",
      "Epoch: 5\tTraining loss: 0.79403\t\t Validation Loss: 0.76317\tValidation Accuracy: 0.84406\n",
      "Epoch: 6\tTraining loss: 0.70736\t\t Validation Loss: 0.70509\tValidation Accuracy: 0.86783\n",
      "Epoch: 7\tTraining loss: 0.66376\t\t Validation Loss: 0.65255\tValidation Accuracy: 0.80464\n",
      "Epoch: 8\tTraining loss: 0.62284\t\t Validation Loss: 0.62668\tValidation Accuracy: 0.87420\n",
      "Epoch: 9\tTraining loss: 0.55287\t\t Validation Loss: 0.56117\tValidation Accuracy: 0.90435\n",
      "Epoch: 10\tTraining loss: 0.52948\t\t Validation Loss: 0.55254\tValidation Accuracy: 0.87478\n",
      "Epoch: 11\tTraining loss: 0.48853\t\t Validation Loss: 0.50130\tValidation Accuracy: 0.86261\n",
      "Epoch: 12\tTraining loss: 0.52056\t\t Validation Loss: 0.50818\tValidation Accuracy: 0.86667\n",
      "Epoch: 13\tTraining loss: 0.42839\t\t Validation Loss: 0.45432\tValidation Accuracy: 0.91188\n",
      "Epoch: 14\tTraining loss: 0.41075\t\t Validation Loss: 0.44754\tValidation Accuracy: 0.91884\n",
      "Epoch: 15\tTraining loss: 0.37318\t\t Validation Loss: 0.35737\tValidation Accuracy: 0.93449\n",
      "Epoch: 16\tTraining loss: 0.65030\t\t Validation Loss: 0.52919\tValidation Accuracy: 0.88522\n",
      "Epoch: 17\tTraining loss: 0.48989\t\t Validation Loss: 0.49039\tValidation Accuracy: 0.91420\n",
      "Epoch: 18\tTraining loss: 0.42017\t\t Validation Loss: 0.36861\tValidation Accuracy: 0.92696\n",
      "Epoch: 19\tTraining loss: 0.33976\t\t Validation Loss: 0.35344\tValidation Accuracy: 0.93449\n",
      "Epoch: 20\tTraining loss: 0.32083\t\t Validation Loss: 0.45900\tValidation Accuracy: 0.89623\n",
      "Epoch: 21\tTraining loss: 0.32766\t\t Validation Loss: 0.34391\tValidation Accuracy: 0.92754\n",
      "Epoch: 22\tTraining loss: 0.28702\t\t Validation Loss: 0.33916\tValidation Accuracy: 0.94319\n",
      "Epoch: 23\tTraining loss: 0.25506\t\t Validation Loss: 0.35207\tValidation Accuracy: 0.86087\n",
      "Epoch: 24\tTraining loss: 0.26969\t\t Validation Loss: 0.34645\tValidation Accuracy: 0.91652\n",
      "Epoch: 25\tTraining loss: 0.24593\t\t Validation Loss: 0.28539\tValidation Accuracy: 0.94551\n",
      "Epoch: 26\tTraining loss: 0.22362\t\t Validation Loss: 0.37750\tValidation Accuracy: 0.95652\n",
      "Epoch: 27\tTraining loss: 0.22369\t\t Validation Loss: 0.36565\tValidation Accuracy: 0.93043\n",
      "Epoch: 28\tTraining loss: 0.23343\t\t Validation Loss: 0.34848\tValidation Accuracy: 0.94493\n",
      "Epoch: 29\tTraining loss: 0.22933\t\t Validation Loss: 0.30031\tValidation Accuracy: 0.96000\n",
      "Epoch: 30\tTraining loss: 0.20121\t\t Validation Loss: 0.30272\tValidation Accuracy: 0.94667\n",
      "Epoch: 31\tTraining loss: 0.22208\t\t Validation Loss: 0.29457\tValidation Accuracy: 0.93101\n",
      "Epoch: 32\tTraining loss: 0.22583\t\t Validation Loss: 0.32414\tValidation Accuracy: 0.91014\n",
      "Epoch: 33\tTraining loss: 0.18538\t\t Validation Loss: 0.30735\tValidation Accuracy: 0.93739\n",
      "Epoch: 34\tTraining loss: 0.16441\t\t Validation Loss: 0.26902\tValidation Accuracy: 0.95130\n",
      "Epoch: 35\tTraining loss: 0.15168\t\t Validation Loss: 0.32229\tValidation Accuracy: 0.92290\n",
      "Epoch: 36\tTraining loss: 0.17236\t\t Validation Loss: 0.33814\tValidation Accuracy: 0.94783\n",
      "Epoch: 37\tTraining loss: 0.16371\t\t Validation Loss: 0.27704\tValidation Accuracy: 0.95362\n",
      "Epoch: 38\tTraining loss: 0.12417\t\t Validation Loss: 0.32033\tValidation Accuracy: 0.95942\n",
      "Epoch: 39\tTraining loss: 0.12713\t\t Validation Loss: 0.30522\tValidation Accuracy: 0.95768\n",
      "Epoch: 40\tTraining loss: 0.15790\t\t Validation Loss: 0.31136\tValidation Accuracy: 0.95130\n",
      "Epoch: 41\tTraining loss: 0.16522\t\t Validation Loss: 0.28185\tValidation Accuracy: 0.95478\n",
      "Epoch: 42\tTraining loss: 0.15004\t\t Validation Loss: 0.30245\tValidation Accuracy: 0.94841\n",
      "Epoch: 43\tTraining loss: 0.14201\t\t Validation Loss: 0.31777\tValidation Accuracy: 0.94261\n",
      "Epoch: 44\tTraining loss: 0.11768\t\t Validation Loss: 0.30863\tValidation Accuracy: 0.95362\n",
      "Epoch: 45\tTraining loss: 0.09965\t\t Validation Loss: 0.36956\tValidation Accuracy: 0.89913\n",
      "Epoch: 46\tTraining loss: 0.11181\t\t Validation Loss: 0.29282\tValidation Accuracy: 0.93797\n",
      "Epoch: 47\tTraining loss: 0.10915\t\t Validation Loss: 0.39642\tValidation Accuracy: 0.94609\n",
      "Epoch: 48\tTraining loss: 0.08558\t\t Validation Loss: 0.38265\tValidation Accuracy: 0.95768\n",
      "Epoch: 49\tTraining loss: 0.09737\t\t Validation Loss: 0.36913\tValidation Accuracy: 0.96232\n",
      "Epoch: 50\tTraining loss: 0.07441\t\t Validation Loss: 0.36057\tValidation Accuracy: 0.95362\n",
      "Epoch: 51\tTraining loss: 0.08810\t\t Validation Loss: 0.37388\tValidation Accuracy: 0.96174\n",
      "Epoch: 52\tTraining loss: 0.11984\t\t Validation Loss: 0.37989\tValidation Accuracy: 0.95652\n",
      "Epoch: 53\tTraining loss: 0.09175\t\t Validation Loss: 0.32838\tValidation Accuracy: 0.95942\n",
      "Epoch: 54\tTraining loss: 0.07264\t\t Validation Loss: 0.38290\tValidation Accuracy: 0.96116\n",
      "Epoch: 55\tTraining loss: 0.09893\t\t Validation Loss: 0.42356\tValidation Accuracy: 0.90435\n",
      "Epoch: 56\tTraining loss: 0.16010\t\t Validation Loss: 0.35029\tValidation Accuracy: 0.93159\n",
      "Epoch: 57\tTraining loss: 0.09622\t\t Validation Loss: 0.45115\tValidation Accuracy: 0.96174\n",
      "Epoch: 58\tTraining loss: 0.20203\t\t Validation Loss: 0.27957\tValidation Accuracy: 0.95304\n",
      "Epoch: 59\tTraining loss: 0.07917\t\t Validation Loss: 0.34558\tValidation Accuracy: 0.96232\n",
      "Epoch: 60\tTraining loss: 0.06218\t\t Validation Loss: 0.31976\tValidation Accuracy: 0.95652\n",
      "Epoch: 61\tTraining loss: 0.06284\t\t Validation Loss: 0.37776\tValidation Accuracy: 0.95478\n",
      "Epoch: 62\tTraining loss: 0.16092\t\t Validation Loss: 0.36639\tValidation Accuracy: 0.92464\n",
      "Epoch: 63\tTraining loss: 0.08526\t\t Validation Loss: 0.35038\tValidation Accuracy: 0.96000\n",
      "Epoch: 64\tTraining loss: 0.03918\t\t Validation Loss: 0.34819\tValidation Accuracy: 0.96058\n",
      "Epoch: 65\tTraining loss: 0.03795\t\t Validation Loss: 0.34582\tValidation Accuracy: 0.96000\n",
      "Epoch: 66\tTraining loss: 0.03206\t\t Validation Loss: 0.38067\tValidation Accuracy: 0.96058\n",
      "Epoch: 67\tTraining loss: 0.02728\t\t Validation Loss: 0.34456\tValidation Accuracy: 0.94841\n",
      "Epoch: 68\tTraining loss: 0.04493\t\t Validation Loss: 0.45523\tValidation Accuracy: 0.95942\n",
      "Epoch: 69\tTraining loss: 0.03803\t\t Validation Loss: 0.43075\tValidation Accuracy: 0.96232\n",
      "Epoch: 70\tTraining loss: 0.05057\t\t Validation Loss: 0.41374\tValidation Accuracy: 0.94203\n",
      "Epoch: 71\tTraining loss: 0.06522\t\t Validation Loss: 0.42449\tValidation Accuracy: 0.94609\n",
      "Epoch: 72\tTraining loss: 0.04485\t\t Validation Loss: 0.39362\tValidation Accuracy: 0.96406\n",
      "Epoch: 73\tTraining loss: 0.06844\t\t Validation Loss: 0.37036\tValidation Accuracy: 0.95884\n",
      "Epoch: 74\tTraining loss: 0.03496\t\t Validation Loss: 0.44071\tValidation Accuracy: 0.96696\n",
      "Saved model successfully!\n"
     ]
    }
   ],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, device: str=\"cpu\", dropout: float=0.2):\n",
    "        super().__init__()\n",
    "        self.device_ = device\n",
    "\n",
    "        self.hidden_size = 256\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.projection = nn.Linear(1, self.hidden_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.hidden_size, hidden_size=self.hidden_size, num_layers=2, dropout=dropout, batch_first=True)\n",
    "\n",
    "\n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, X: torch.FloatTensor):\n",
    "        out = self.dropout1(self.tanh(self.projection(X)))\n",
    "        out, (_, _) = self.lstm(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "    \n",
    "    def predict_batch(self, X: torch.FloatTensor):\n",
    "        pred = (torch.sigmoid(self(X)) > 0.5).int()\n",
    "        return pred\n",
    "    \n",
    "    def predict(self, dataloader: DataLoader):\n",
    "        predictions = list()\n",
    "        for i, data in enumerate(dataloader, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            with torch.no_grad():\n",
    "                X = data[\"X\"]\n",
    "                y_pred = self.predict_batch(X)\n",
    "                predictions.append(y_pred)\n",
    "        predictions = torch.cat(predictions, 0)\n",
    "        return predictions\n",
    "\n",
    "    def to_string(self):\n",
    "        return \"LSTMClassifier\"\n",
    "\n",
    "\n",
    "model_lstm = LSTMClassifier(device=DEVICE, dropout=0.25)\n",
    "state_lstm = training(model_lstm, train_dataloader, val_dataloader, device=DEVICE, epochs=NUM_EPOCHS, lr=LEARNING_RATE, earlystopping_tolerance=NUM_EPOCHS)\n",
    "# print(X_train[:32].shape)\n",
    "# model(X_train[:32]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf8225",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89c218e4cc41e884f86683685cebc6d3a872232fe925e4ab554e8abe484c931d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
